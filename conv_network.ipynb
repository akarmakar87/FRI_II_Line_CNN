{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import preprocessing as p\n",
    "import gc\n",
    "import cv2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA PREPROCESSING: NORMALIZE THE DATA ###\n",
    "\n",
    "min_max_scaler = p.MinMaxScaler()\n",
    "INPUT_DATA_PATH = 'test_input_new.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output_new.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "y_input = np.load(OUTPUT_DATA_PATH)\n",
    "\n",
    "x_min = x_input.min(axis=(1, 2), keepdims=True)\n",
    "x_max = x_input.max(axis=(1, 2), keepdims=True)\n",
    "x_input = (x_input - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y_input.min(axis=(1, 2), keepdims=True)\n",
    "y_max = y_input.max(axis=(1, 2), keepdims=True)\n",
    "y_input = (y_input - y_min)/(y_max-y_min)\n",
    "\n",
    "num_points = np.load('test_nums.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "SPLIT_IDX = 7500\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "test_num_points = num_points[SPLIT_IDX:]\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(5,5), stride=1, bias=True, padding=(2,2)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(7,7), stride=1, bias=True, padding=(3,3)),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(9,9), stride=1, bias=True, padding=(4,4)), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(11,11), padding=(5,5)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRE-TRAINED MODEL ###\n",
    "model = torch.load('model_final_new_layers.pt')\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "learning_rate = 3e-4\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=weight_decay, lr=learning_rate)\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "loss_fn = nn.MSELoss()\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_input(model_input):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "\n",
    "    model_input[model_input != BLACK] = WHITE\n",
    "\n",
    "def threshold_output(model_output):\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "    model_output[model_output <= THRESHOLD] = BLACK\n",
    "\n",
    "def mask(thresholded_input, model_output):\n",
    "    return np.logical_or(thresholded_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    avg_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = avg_loss / size\n",
    "    print(f\"average loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    pcnt_false_negatives = 0\n",
    "    pcnt_false_positives = 0\n",
    "    size = len(test_dataloader.dataset)\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            raw_output = model(data)\n",
    "            # print(output*255)\n",
    "            for out_i in range(100):\n",
    "                input = np.array(data.cpu().data[out_i][0])\n",
    "                output = np.array(raw_output.cpu().data[out_i][0])\n",
    "                threshold_input(input)\n",
    "                threshold_output(output)\n",
    "\n",
    "                # mask the input onto the output to isolate the black points\n",
    "                final_output = mask(input, output)\n",
    "                # number of points the model counted\n",
    "                num_total = np.count_nonzero(final_output == 0.0)\n",
    "                # mask the target onto the final output to check \n",
    "                masked_target = mask(np.array(target.cpu().data[out_i])[0], final_output)\n",
    "                # number of points IN THE LINE the model counted \n",
    "                num_in_line = np.count_nonzero(masked_target == 0.0)\n",
    "                # num_expected = test_num_points[i]\n",
    "\n",
    "                num_expected_in_line = test_num_points[i][0]\n",
    "                num_expected_outside_line = test_num_points[i][1]\n",
    "\n",
    "                # (expected positive - actual positive) / expected posiitive\n",
    "                num_missed_in_line = num_expected_in_line - num_in_line\n",
    "                pcnt_false_negatives += num_missed_in_line / num_expected_in_line\n",
    "\n",
    "\n",
    "                # (actual negative) / expected posiitive\n",
    "                num_identified_outside = num_total - num_in_line\n",
    "                pcnt_false_positives += num_identified_outside / num_expected_outside_line\n",
    "\n",
    "                # if (i == t):\n",
    "                #     print(f\"# false negatives: {num_missed_in_line}\")\n",
    "                #     print(f\"# false positives: {num_identified_outside}\")\n",
    "                #     print(f\"num expected in line: {num_expected_in_line}. num counted in line: {num_in_line}\")\n",
    "                #     print(f\"num expected outside line: {num_expected_outside_line}. num counted outside line: {(num_expected_outside_line + num_expected_in_line) - num_in_line}\")\n",
    "\n",
    "                #     data_img = Image.fromarray(input*255)\n",
    "                #     data_img.show()\n",
    "\n",
    "                #     output_img = Image.fromarray(output*255)\n",
    "                #     output_img.show()\n",
    "\n",
    "                #     masked = Image.fromarray(final_output.astype(np.uint8)*255)\n",
    "                #     masked.show()\n",
    "\n",
    "                i += 1\n",
    "    pcnt_false_negatives = pcnt_false_negatives / size\n",
    "    pcnt_false_positives = pcnt_false_positives / size\n",
    "    print(f\"Average percent false negatives: {pcnt_false_negatives}\")\n",
    "    print(f\"Average percent false positives: {pcnt_false_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TRAINING ONLY ###\n",
    "\n",
    "# # test()\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#     # test(500)\n",
    "#     # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percent false negatives: 0.06653022200022195\n",
      "Average percent false positives: 0.010407142857142847\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "num counted: 6, num expected:[6. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:10323): Gtk-WARNING **: 15:34:59.723: Could not load a pixbuf from icon theme.\n",
      "This may indicate that pixbuf loaders or the mime database could not be found.\n"
     ]
    }
   ],
   "source": [
    "### DEBUGGING PURPOSES ONLY ###\n",
    "\n",
    "i = randint(0,99)\n",
    "i = 36\n",
    "print (i)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        raw_output = model(data)    \n",
    "        normOutput = (raw_output-raw_output.min())/(raw_output.max()-raw_output.min())\n",
    "\n",
    "        target_arr = np.array(target.cpu().data[i][0])\n",
    "\n",
    "        # INPUT\n",
    "        input_arr = np.array(data.cpu().data[i][0])\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "\n",
    "        # OUTPUT\n",
    "        output_arr = np.array(normOutput.cpu().data[i][0])\n",
    "        output = Image.fromarray(output_arr * 255)\n",
    "    \n",
    "        threshold_input(input_arr)\n",
    "        threshold_output(output_arr)\n",
    "\n",
    "        input.show()\n",
    "        output.show()\n",
    "\n",
    "        masked_arr = mask(input_arr, output_arr)\n",
    "        # print (masked_arr.astype(float))\n",
    "        masked = Image.fromarray((masked_arr.astype(np.uint8) * 255))\n",
    "        masked.show()\n",
    "\n",
    "        num_dots = np.count_nonzero(masked_arr == 0.0)\n",
    "        num_expected = test_num_points[i]\n",
    "\n",
    "\n",
    "        target = Image.fromarray(target_arr*255)\n",
    "        target.show()\n",
    "\n",
    "\n",
    "        final_output = mask(input_arr, output_arr)\n",
    "        # number of points the model counted\n",
    "        # num_total = np.count_nonzero(final_output == 0.0)\n",
    "        # mask the target onto the final output to check \n",
    "        masked_target = mask(target_arr, final_output)\n",
    "        masked_target_img = Image.fromarray(masked_target.astype(np.uint8)*255)\n",
    "        masked_target_img.show()\n",
    "        \n",
    "        #  number of points IN THE LINE the model counted \n",
    "        # num_in_line = np.count_nonzero(masked_target == 0.0)\n",
    "        # num_expected = test_num_points[i]\n",
    "        print(f\"num counted: {num_dots}, num expected:{num_expected}\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'model_final_new_layers.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c6b82f28f63ce523f5c26d92ac0b14ad6785c6a25a5c8f6e4c562a3fc2245a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
