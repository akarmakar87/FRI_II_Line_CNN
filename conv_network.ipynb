{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import preprocessing as p\n",
    "import gc\n",
    "import cv2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1648"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = p.MinMaxScaler()\n",
    "INPUT_DATA_PATH = 'test_input_new.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output_new.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "y_input = np.load(OUTPUT_DATA_PATH)\n",
    "\n",
    "x_min = x_input.min(axis=(1, 2), keepdims=True)\n",
    "x_max = x_input.max(axis=(1, 2), keepdims=True)\n",
    "x_input = (x_input - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y_input.min(axis=(1, 2), keepdims=True)\n",
    "y_max = y_input.max(axis=(1, 2), keepdims=True)\n",
    "y_input = (y_input - y_min)/(y_max-y_min)\n",
    "\n",
    "num_points = np.load('test_nums.npy')\n",
    "# print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input[x_input < 1] = 0\n",
    "\n",
    "\n",
    "# print(x_input[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(tensor):\n",
    "    for img in range(len(tensor)):\n",
    "            for channel in range(1):\n",
    "                    for h in range(100):\n",
    "                            for w in range(100):\n",
    "                                    if (tensor[img][channel][h][w] < 1):\n",
    "                                            tensor[img][channel][h][w] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "SPLIT_IDX = 7500\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "test_num_points = num_points[SPLIT_IDX:]\n",
    "\n",
    "# print (test_num_points.shape)\n",
    "\n",
    "# threshold(x_train)                       \n",
    "# threshold(x_test)\n",
    "# threshold(y_train)                       \n",
    "# threshold(y_test)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "#/home/bwilab/asha_ritu/line_model/conv_network.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(6,6), stride=1, bias=True, padding=(2,2)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "learning_rate = 3e-4\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=weight_decay, lr=learning_rate)\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    avg_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "        #     print(f\"loss: {loss:>7f}\")\n",
    "    avg_loss = avg_loss / size\n",
    "    print(f\"average loss: {avg_loss}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "average loss: 0.001422505360096693\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "average loss: 0.0001423154171789065\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "average loss: 3.59611221938394e-05\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "average loss: 1.924431671795901e-05\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "average loss: 1.4792006368224975e-05\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "average loss: 1.2342615264060441e-05\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "average loss: 1.0573092367849313e-05\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "average loss: 9.586331543687265e-06\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "average loss: 8.290862751891837e-06\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "average loss: 7.62083800509572e-06\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "average loss: 7.0486653385160025e-06\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "average loss: 6.548264536831994e-06\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "average loss: 6.235692126210779e-06\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "average loss: 8.831781087792479e-06\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "average loss: 5.61426168133039e-06\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "average loss: 5.316169335856102e-06\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "average loss: 5.101787792227697e-06\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "average loss: 4.900478870695224e-06\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "average loss: 4.720496235677274e-06\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "average loss: 4.572658781398786e-06\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "average loss: 4.436973995325388e-06\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "average loss: 4.23038363805972e-06\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "average loss: 4.295844064472476e-06\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "average loss: 4.092152266821358e-06\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "average loss: 3.971684691350674e-06\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "average loss: 3.886505965056131e-06\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "average loss: 5.240234713710379e-06\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "average loss: 5.466498350870097e-06\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "average loss: 3.409190412639873e-06\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "average loss: 3.289005917395116e-06\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# test()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test(500)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "# model = torch.load('model_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_input(model_input):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "\n",
    "    model_input[model_input != BLACK] = WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_output(model_output):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "    model_output[model_output <= THRESHOLD] = BLACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(thresholded_input, model_output):\n",
    "    return np.logical_or(thresholded_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    avg_outside_line = 0\n",
    "    avg_missed_in_line = 0\n",
    "    size = len(test_dataloader.dataset)\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            # print(output*255)\n",
    "            for out_i in range(100):\n",
    "                # mask the input onto the output to isolate the black points\n",
    "                final_output = mask(np.array(data.cpu().data[out_i][0]), np.array(output.cpu().data[out_i][0]))\n",
    "                # number of points the model counted\n",
    "                num_total = np.count_nonzero(final_output == 0.0)\n",
    "                # mask the target onto the final output to check \n",
    "                masked_target = mask(np.array(target.cpu().data[out_i])[0], final_output)\n",
    "                # number of points IN THE LINE the model counted \n",
    "                num_in_line = np.count_nonzero(masked_target == 0.0)\n",
    "                # num_expected = test_num_points[i]\n",
    "                \n",
    "                # curr_diff = math.sqrt((num_counted - num_expected)**2)\n",
    "                # if (out_i % 50 == 0):\n",
    "                #     print(f\"diff: {curr_diff}\")\n",
    "            \n",
    "                # print(f\"accuracy of this trial: {(num_dots - num_expected)/num_expected * 100}\")\n",
    "                # avg_accuracy += curr_diff\n",
    "                i += 1\n",
    "    avg_outside_line = avg_outside_line / size\n",
    "    avg_missed_in_line = avg_missed_in_line / size\n",
    "    print(f\"Average number of points misidentified (false positives): {avg_outside_line}\")\n",
    "    print(f\"Average number of points missed (false negatives): {avg_missed_in_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of points misidentified (false positives): 0.0096\n",
      "Average number of points missed (false negatives): 3.4308\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "num counted: 8, num expected:4.0\n"
     ]
    }
   ],
   "source": [
    "i = randint(0,99)\n",
    "i = 96\n",
    "print (i)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        raw_output = model(data)    \n",
    "        normOutput = (raw_output-raw_output.min())/(raw_output.max()-raw_output.min())\n",
    "\n",
    "        target_arr = np.array(target.cpu().data[i][0])\n",
    "\n",
    "        # INPUT\n",
    "        input_arr = np.array(data.cpu().data[i][0])\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "\n",
    "        # OUTPUT\n",
    "        output_arr = np.array(normOutput.cpu().data[i][0])\n",
    "        output = Image.fromarray(output_arr * 255)\n",
    "    \n",
    "        threshold_input(input_arr)\n",
    "        threshold_output(output_arr)\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "        input.show()\n",
    "        output.show()\n",
    "\n",
    "        masked_arr = mask(input_arr, output_arr)\n",
    "        # print (masked_arr.astype(float))\n",
    "        masked = Image.fromarray((masked_arr * 255).astype(np.uint8))\n",
    "        masked.show()\n",
    "\n",
    "        num_dots = np.count_nonzero(masked_arr == 0.0)\n",
    "        num_expected = test_num_points[i]\n",
    "\n",
    "\n",
    "        target = Image.fromarray(target_arr*255)\n",
    "        target.show()\n",
    "\n",
    "\n",
    "        final_output = mask(input_arr, output_arr)\n",
    "        # number of points the model counted\n",
    "        # num_total = np.count_nonzero(final_output == 0.0)\n",
    "        # mask the target onto the final output to check \n",
    "        masked_target = mask(target_arr, final_output)\n",
    "        masked_target_img = Image.fromarray(masked_target)\n",
    "        masked_target_img.show()\n",
    "        \n",
    "        #  number of points IN THE LINE the model counted \n",
    "        # num_in_line = np.count_nonzero(masked_target == 0.0)\n",
    "        # num_expected = test_num_points[i]\n",
    "        print(f\"num counted: {num_dots}, num expected:{num_expected}\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:1311405): Gtk-WARNING **: 18:49:00.900: Could not load a pixbuf from icon theme.\n",
      "This may indicate that pixbuf loaders or the mime database could not be found.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'model_final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c6b82f28f63ce523f5c26d92ac0b14ad6785c6a25a5c8f6e4c562a3fc2245a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
