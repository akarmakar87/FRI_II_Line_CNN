{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 576, 576, 3)\n",
      "(20, 576, 576, 3)\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA_PATH = 'test_input.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "print (x_input.shape)\n",
    "y_input = np.load(OUTPUT_DATA_PATH) #np.array([randint(0, 3) for _ in range(len(x_input))])\n",
    "#np.load(OUTPUT_DATA_PATH)\n",
    "print (y_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 576, 576, 3])\n",
      "torch.Size([15, 3, 576, 576])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "SPLIT_IDX = 15 #750\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float)\n",
    "print (x_train.shape)\n",
    "x_train = x_train.permute(0, 3, 1, 2) # from NHWC to NCHW\n",
    "print (x_train.shape)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0, 3, 1, 2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float)#.permute(0, 3, 1, 2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float)#.permute(0, 3, 1, 2)\n",
    "\n",
    "class LinesDataset(TensorDataset):\n",
    "        def __init__(self, lines, labels):\n",
    "                self.lines = lines\n",
    "                self.labels = labels\n",
    "        def __len__(self):\n",
    "                return len(self.lines)\n",
    "        def __getitem__(self, idx):\n",
    "                line = torch.tensor(self.lines[idx])\n",
    "                label = torch.tensor(self.labels[idx])\n",
    "                sample = {\"Line\": line, \"Label\": label}\n",
    "                return sample\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_channels, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channels, out_channels=1, kernel_size=(9,9), stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None),\n",
    "            # convolutional layers + activation functions and pooling layers in between\n",
    "            # nn.Conv2d(in_channels=input_channels, out_channels=1, kernel_size=(9,9), stride=(1,1))\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        print(X.shape)\n",
    "        pred = model(X)\n",
    "        # print(f\"predicted: {pred}\")\n",
    "        # # print(f\"actual: {y}\")\n",
    "        loss =  F.nll_loss(pred, y)\n",
    "        #loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(3, (576, 576))\n",
    "learning_rate = 0.001\n",
    "batch_size = 5\n",
    "epochs = 5\n",
    "# Initialize the loss function\n",
    "# loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.CrossEntropyLoss() # can change this to another loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "torch.Size([5, 3, 576, 576])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m      4\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [22], line 12\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     10\u001b[0m \u001b[39m# print(f\"predicted: {pred}\")\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# # print(f\"actual: {y}\")\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m loss \u001b[39m=\u001b[39m  F\u001b[39m.\u001b[39;49mnll_loss(pred, y)\n\u001b[0;32m     13\u001b[0m \u001b[39m#loss_fn(pred, y)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\ashak\\OneDrive\\Documents\\GitHub\\line_model\\torchy\\lib\\site-packages\\torch\\nn\\functional.py:2701\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2699\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2700\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2701\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 4"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torchy': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "185bff9e47624383988f382822b06e038e14ebe66f2cf790e212a63ae94a53d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
