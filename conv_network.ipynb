{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import preprocessing as p\n",
    "import gc\n",
    "import cv2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = p.MinMaxScaler()\n",
    "INPUT_DATA_PATH = 'test_input_new.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output_new.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "y_input = np.load(OUTPUT_DATA_PATH)\n",
    "\n",
    "x_min = x_input.min(axis=(1, 2), keepdims=True)\n",
    "x_max = x_input.max(axis=(1, 2), keepdims=True)\n",
    "x_input = (x_input - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y_input.min(axis=(1, 2), keepdims=True)\n",
    "y_max = y_input.max(axis=(1, 2), keepdims=True)\n",
    "y_input = (y_input - y_min)/(y_max-y_min)\n",
    "\n",
    "num_points = np.load('test_nums.npy')\n",
    "# print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input[x_input < 1] = 0\n",
    "\n",
    "\n",
    "# print(x_input[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(tensor):\n",
    "    for img in range(len(tensor)):\n",
    "            for channel in range(1):\n",
    "                    for h in range(100):\n",
    "                            for w in range(100):\n",
    "                                    if (tensor[img][channel][h][w] < 1):\n",
    "                                            tensor[img][channel][h][w] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "SPLIT_IDX = 7500\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "test_num_points = num_points[SPLIT_IDX:]\n",
    "\n",
    "# print (test_num_points.shape)\n",
    "\n",
    "# threshold(x_train)                       \n",
    "# threshold(x_test)\n",
    "# threshold(y_train)                       \n",
    "# threshold(y_test)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "#/home/bwilab/asha_ritu/line_model/conv_network.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            # first layer: learning one person. \n",
    "            # kernel size = diameter of a dot (5 pixels) + padding (2 pixels) = (7,7)\n",
    "            # out_channels: 1 for now\n",
    "            # try changing the out_channels\n",
    "            # larger dataset and ReLU between each layer\n",
    "            # larger dataset, more layers, larger kernels\n",
    "\n",
    "            # find center pixel of each circle, count number of dots\n",
    "\n",
    "            # blob detect: looking for continuous regions of non-white pixels\n",
    "            # confidence regions. \n",
    "            # masking the image like in hw3\n",
    "            # \n",
    "            # nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(2,2), stride=1, bias=True, padding=(0,0)), # input layer\n",
    "            # nn.ReLU(),\n",
    "\n",
    "            # nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            # nn.ReLU(),\n",
    "\n",
    "            # nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(19,19), stride=1, bias=True, padding=(9,9)), # input layer nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            nn.ReLU()\n",
    "            # nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            # nn.ReLU()\n",
    "            \n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(6,6), stride=1, bias=True, padding=(2,2)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(19,19), stride=1, bias=True, padding=(9,9)), # input layer\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            nn.ReLU()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "learning_rate = 3e-4\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=weight_decay, lr=learning_rate)\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss() # can change this to another loss function\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    avg_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        # print(X)\n",
    "        pred = model(X)\n",
    "        # print(f\"pred:{pred}\")\n",
    "        # print(f\"target:{y}\")\n",
    "    \n",
    "        # print(f\"pred: {pred}\")\n",
    "        # print(f\"y shape:{y.shape}\")\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "        #     print(f\"loss: {loss:>7f}\")\n",
    "    avg_loss = avg_loss / size\n",
    "    print(f\"average loss: {avg_loss}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    avg_accuracy = 0\n",
    "    size = len(test_dataloader.dataset)\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            # print(output*255)\n",
    "            for out_i in range(100):\n",
    "                \n",
    "                masked_arr = mask(np.array(data.cpu().data[out_i][0]), np.array(output.cpu().data[out_i][0]))\n",
    "                num_dots = np.count_nonzero(masked_arr != 0.0)\n",
    "                num_expected = test_num_points[i]\n",
    "                \n",
    "                curr_diff = (num_dots - num_expected)**2\n",
    "                if (out_i % 50 == 0):\n",
    "                    print(f\"diff: {curr_diff}\")\n",
    "                # num_expected = np.count_nonzero(np.array(target.cpu().data[out_i][0]) == 0.0)\n",
    "\n",
    "                # print(np.array(target.cpu().data[out_i][0]).shape)\n",
    "                # if (i == t):\n",
    "                #     print(f\"num counted: {num_dots}, num expected:{num_expected}\")\n",
    "\n",
    "                #     im = Image.fromarray(np.array(data.cpu().data[out_i][0])*255)\n",
    "                #     im.show()\n",
    "\n",
    "                # print(f\"accuracy of this trial: {(num_dots - num_expected)/num_expected * 100}\")\n",
    "                avg_accuracy += curr_diff\n",
    "                i += 1\n",
    "    avg_accuracy = math.sqrt(avg_accuracy / size)\n",
    "    print(f\"RMSE accuracy: {avg_accuracy}\")\n",
    "\n",
    "# test(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_num_points[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "average loss: 0.0010806085774675012\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "average loss: 6.735212082276121e-05\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "average loss: 2.4535034754080698e-05\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "average loss: 1.9509603589540347e-05\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "average loss: 1.7081127225537784e-05\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "average loss: 1.5627543689333834e-05\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "average loss: 1.4375136743183248e-05\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "average loss: 1.3296492397785187e-05\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "average loss: 1.2266623343748506e-05\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "average loss: 1.1409091712266672e-05\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "average loss: 1.0580390153336339e-05\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "average loss: 9.792831406230107e-06\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "average loss: 9.050773769558873e-06\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "average loss: 8.334946869581472e-06\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "average loss: 7.625928901688894e-06\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "average loss: 5.833715476910584e-06\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "average loss: 4.7140897549979854e-06\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "average loss: 4.223676569381496e-06\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "average loss: 3.90935429095407e-06\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "average loss: 3.693244707392296e-06\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "average loss: 3.554712293407647e-06\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "average loss: 3.4227452943014214e-06\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "average loss: 4.1481621337879915e-06\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "average loss: 3.208766656825901e-06\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "average loss: 3.1287138426705496e-06\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "average loss: 3.0975070330896415e-06\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "average loss: 3.004239943038556e-06\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "average loss: 3.009775809914572e-06\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "average loss: 2.9171421829232713e-06\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "average loss: 2.9189670840423787e-06\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# test()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test(500)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_input(model_input):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "\n",
    "    model_input[model_input != BLACK] = WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_output(model_output):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "    model_output[model_output <= THRESHOLD] = BLACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(thresholded_input, model_output):\n",
    "    WHITE = 1\n",
    "    # BLACK = 0\n",
    "    # THRESHOLD = 0.5\n",
    "\n",
    "    # model_output = 1-model_output\n",
    "    # model_input = 1-model_input\n",
    "\n",
    "    # model_output[model_output > 0.5] = WHITE\n",
    "    # model_input[model_output > 0.5] = WHITE\n",
    "\n",
    "    # # print (model_input)\n",
    "\n",
    "    # # for i in model_input:\n",
    "    # #     for j in i:\n",
    "    # #         if j  1:\n",
    "    # #             print (j)\n",
    "\n",
    "    # input = Image.fromarray(model_input * 255)\n",
    "    # input.show()\n",
    "    \n",
    "\n",
    "    masked_arr = np.logical_or(thresholded_input, model_output)\n",
    "    \n",
    "    # print(m)\n",
    "    return masked_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "num counted: 9991, num expected:7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:1303216): GLib-GObject-CRITICAL **: 17:38:27.683: g_object_unref: assertion 'G_IS_OBJECT (object)' failed\n",
      "\n",
      "(eog:1303216): EOG-WARNING **: 17:38:27.683: Error when getting information for file “/tmp/.gnome_desktop_thumbnail.UKICW1”: No such file or directory\n",
      "\n",
      "(eog:1303216): EOG-CRITICAL **: 17:38:27.710: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:1303216): GLib-GIO-CRITICAL **: 17:38:27.710: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n"
     ]
    }
   ],
   "source": [
    "i = randint(0,100)\n",
    "print (i)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        raw_output = model(data)    \n",
    "        normOutput = (raw_output-raw_output.min())/(raw_output.max()-raw_output.min())\n",
    "\n",
    "        # INPUT\n",
    "        input_arr = np.array(data.cpu().data[i][0])\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "        # input.show()\n",
    "\n",
    "        # OUTPUT\n",
    "        output_arr = np.array(normOutput.cpu().data[i][0])\n",
    "        output = Image.fromarray(output_arr * 255)\n",
    "        output.show()\n",
    "    \n",
    "        threshold_input(input_arr)\n",
    "        threshold_output(output_arr)\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "        input.show()\n",
    "\n",
    "        masked_arr = mask(input_arr, output_arr)\n",
    "        # print (masked_arr.astype(float))\n",
    "        masked = Image.fromarray((masked_arr * 255).astype(np.uint8))\n",
    "        masked.show()\n",
    "\n",
    "        num_dots = np.count_nonzero(masked_arr == 0.0)\n",
    "        num_expected = test_num_points[i]\n",
    "        print(f\"num counted: {num_dots}, num expected:{num_expected}\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test()\n",
    "# test()\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     # train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#     test()\n",
    "#     # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "# print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c6b82f28f63ce523f5c26d92ac0b14ad6785c6a25a5c8f6e4c562a3fc2245a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
