{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import preprocessing as p\n",
    "import gc\n",
    "import cv2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = p.MinMaxScaler()\n",
    "INPUT_DATA_PATH = 'test_input_new.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output_new.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "y_input = np.load(OUTPUT_DATA_PATH)\n",
    "\n",
    "x_min = x_input.min(axis=(1, 2), keepdims=True)\n",
    "x_max = x_input.max(axis=(1, 2), keepdims=True)\n",
    "x_input = (x_input - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y_input.min(axis=(1, 2), keepdims=True)\n",
    "y_max = y_input.max(axis=(1, 2), keepdims=True)\n",
    "y_input = (y_input - y_min)/(y_max-y_min)\n",
    "\n",
    "num_points = np.load('test_nums.npy')\n",
    "# print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input[x_input < 1] = 0\n",
    "\n",
    "\n",
    "# print(x_input[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(tensor):\n",
    "    for img in range(len(tensor)):\n",
    "            for channel in range(1):\n",
    "                    for h in range(100):\n",
    "                            for w in range(100):\n",
    "                                    if (tensor[img][channel][h][w] < 1):\n",
    "                                            tensor[img][channel][h][w] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_IDX = 7500\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "test_num_points = num_points[SPLIT_IDX:]\n",
    "\n",
    "# print (test_num_points.shape)\n",
    "\n",
    "# threshold(x_train)                       \n",
    "# threshold(x_test)\n",
    "# threshold(y_train)                       \n",
    "# threshold(y_test)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "#/home/bwilab/asha_ritu/line_model/conv_network.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(6,6), stride=1, bias=True, padding=(2,2)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(11,11), stride=1, bias=True, padding=(5,5)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels=10, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "learning_rate = 3e-4\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=weight_decay, lr=learning_rate)\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    avg_loss = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch % 100 == 0:\n",
    "        #     print(f\"loss: {loss:>7f}\")\n",
    "    avg_loss = avg_loss / size\n",
    "    print(f\"average loss: {avg_loss}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average loss: 2.2126047042547725e-05\n",
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[286], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# test(500)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[284], line 10\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m      9\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n\u001b[0;32m---> 10\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m \u001b[39m# if batch % 100 == 0:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     print(f\"loss: {loss:>7f}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/asha_ritu/pyenv/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/asha_ritu/pyenv/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test(500)\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "# model = torch.load('model_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_input(model_input):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "\n",
    "    model_input[model_input != BLACK] = WHITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_output(model_output):\n",
    "    WHITE = 1\n",
    "    BLACK = 0\n",
    "    THRESHOLD = 0.5\n",
    "    model_output[model_output <= THRESHOLD] = BLACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(thresholded_input, model_output):\n",
    "    return np.logical_or(thresholded_input, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    avg_outside_line = 0\n",
    "    avg_missed_in_line = 0\n",
    "    size = len(test_dataloader.dataset)\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            output = model(data)\n",
    "            # print(output*255)\n",
    "            for out_i in range(100):\n",
    "                # mask the input onto the output to isolate the black points\n",
    "                final_output = mask(np.array(data.cpu().data[out_i][0]), np.array(output.cpu().data[out_i][0]))\n",
    "                # number of points the model counted\n",
    "                num_total = np.count_nonzero(final_output == 0.0)\n",
    "                # mask the target onto the final output to check \n",
    "                masked_target = mask(np.array(target.cpu().data[out_i])[0], final_output)\n",
    "                # number of points IN THE LINE the model counted \n",
    "                num_in_line = np.count_nonzero(masked_target == 0.0)\n",
    "\n",
    "                # ideally, 0\n",
    "                num_outside_line = num_total - num_in_line\n",
    "                # difference between the number of points in line the model identified and the target number of points in line. ideally, 0\n",
    "                missed_in_line = test_num_points[i] - num_in_line\n",
    "\n",
    "\n",
    "                avg_outside_line += num_outside_line\n",
    "                avg_missed_in_line += missed_in_line\n",
    "\n",
    "                # num_expected = test_num_points[i]\n",
    "                \n",
    "                # curr_diff = math.sqrt((num_counted - num_expected)**2)\n",
    "                # if (out_i % 50 == 0):\n",
    "                #     print(f\"diff: {curr_diff}\")\n",
    "            \n",
    "                # print(f\"accuracy of this trial: {(num_dots - num_expected)/num_expected * 100}\")\n",
    "                # avg_accuracy += curr_diff\n",
    "                i += 1\n",
    "    avg_outside_line = avg_outside_line / size\n",
    "    avg_missed_in_line = avg_missed_in_line / size\n",
    "    print(f\"Average number of points misidentified (false positives): {avg_outside_line}\")\n",
    "    print(f\"Average number of points missed (false negatives): {avg_missed_in_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = randint(0,100)\n",
    "# i = 80\n",
    "print (i)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        raw_output = model(data)    \n",
    "        normOutput = (raw_output-raw_output.min())/(raw_output.max()-raw_output.min())\n",
    "\n",
    "        # INPUT\n",
    "        input_arr = np.array(data.cpu().data[i][0])\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "        input.show()\n",
    "\n",
    "        # OUTPUT\n",
    "        output_arr = np.array(normOutput.cpu().data[i][0])\n",
    "        output = Image.fromarray(output_arr * 255)\n",
    "        output.show()\n",
    "    \n",
    "        threshold_input(input_arr)\n",
    "        threshold_output(output_arr)\n",
    "        input = Image.fromarray(input_arr * 255)\n",
    "        # input.show()\n",
    "\n",
    "        masked_arr = mask(input_arr, output_arr)\n",
    "        # print (masked_arr.astype(float))\n",
    "        masked = Image.fromarray((masked_arr * 255).astype(np.uint8))\n",
    "        # masked.show()\n",
    "\n",
    "        num_dots = np.count_nonzero(masked_arr == 0.0)\n",
    "        num_expected = test_num_points[i]\n",
    "\n",
    "\n",
    "        target = Image.fromarray(np.array(target.cpu().data[i][0])*255)\n",
    "        # target.show()\n",
    "\n",
    "        print(f\"num counted: {num_dots}, num expected:{num_expected}\")\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c6b82f28f63ce523f5c26d92ac0b14ad6785c6a25a5c8f6e4c562a3fc2245a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
