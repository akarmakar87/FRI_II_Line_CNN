{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_PATH = 'test_input.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "print (x_input.shape)\n",
    "y_input = np.load(OUTPUT_DATA_PATH) #np.array([randint(0, 3) for _ in range(len(x_input))])\n",
    "#np.load(OUTPUT_DATA_PATH)\n",
    "print (y_input.shape)\n",
    "\n",
    "# normalize the inputs to go from 0 to 255 to 0 to 1. divide the input, multiply on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_IDX = 15 #750\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(x_train[0].shape)\n",
    "# print(x_train[0][0].shape)\n",
    "\n",
    "\n",
    "# for img in x_train: # iterate through 15 images\n",
    "#         for h in img[0]:\n",
    "#                 for w in h:\n",
    "#                         if (w < 254):\n",
    "#                                 print (f\"found one! = {w}\")    \n",
    "  \n",
    "class LinesDataset(TensorDataset):\n",
    "        def __init__(self, lines, labels):\n",
    "                self.lines = lines\n",
    "                self.labels = labels\n",
    "        def __len__(self):\n",
    "                return len(self.lines)\n",
    "        def __getitem__(self, idx):\n",
    "                line = torch.tensor(self.lines[idx])\n",
    "                label = torch.tensor(self.labels[idx])\n",
    "                sample = {\"Line\": line, \"Label\": label}\n",
    "                return sample\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            # first kernel size: learning one person. \n",
    "            # size of a dot + 2 pixels of padding\n",
    "            # out_channels: 1 or a few more\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(10,10), stride=1, bias=True, padding=(1,1)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # layer 2: learning two dots. \n",
    "            # kernel_size = size for 2 people + distance + padding\n",
    "\n",
    "            # 8 directions the line could be in\n",
    "            # two options: either increase kernel size and number of channels or\n",
    "            # pool -> lower image resolution and learn a smaller pattern\n",
    "\n",
    "            # final layer: out_channels=1, \n",
    "\n",
    "            nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(10,10), padding=(1,1)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "batch_size = 5\n",
    "epochs = 5\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss() # can change this to another loss function\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        # print(X)\n",
    "        pred = model(X)\n",
    "        # print(pred)\n",
    "      \n",
    "\n",
    "        # print(f\"pred: {pred}\")\n",
    "        # print(f\"y shape:{y.shape}\")\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # print(X.shape)\n",
    "            pred = model(X)\n",
    "            # print(pred.argmax(1).shape)\n",
    "            # print(y.shape)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            # print(correct)\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "      output = model(data)\n",
    "      test_loss += loss_fn(output, target).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      # print(pred)\n",
    "      # print(target)\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "      \n",
    "  test_loss /= len(test_dataloader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_dataloader.dataset),\n",
    "    100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test()\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('pyenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "952863ed7f17ffcbf80d30bf455f69fb2e26b6b85815b8fac0ebd69316f2e222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
