{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURRENTLY WORKING IN THIS ONE\n",
    "import os\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn import preprocessing as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = p.MinMaxScaler()\n",
    "\n",
    "INPUT_DATA_PATH = 'test_input.npy'\n",
    "OUTPUT_DATA_PATH = 'test_output.npy'\n",
    "x_input = np.load(INPUT_DATA_PATH)\n",
    "y_input = np.load(OUTPUT_DATA_PATH)\n",
    "\n",
    "x_min = x_input.min(axis=(1, 2), keepdims=True)\n",
    "x_max = x_input.max(axis=(1, 2), keepdims=True)\n",
    "x_input = (x_input - x_min)/(x_max-x_min)\n",
    "\n",
    "y_min = y_input.min(axis=(1, 2), keepdims=True)\n",
    "y_max = y_input.max(axis=(1, 2), keepdims=True)\n",
    "y_input = (y_input - y_min)/(y_max-y_min)\n",
    "\n",
    "# print(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_input[x_input < 1] = 0\n",
    "\n",
    "\n",
    "# print(x_input[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(tensor):\n",
    "    for img in range(len(tensor)):\n",
    "            for channel in range(1):\n",
    "                    for h in range(100):\n",
    "                            for w in range(100):\n",
    "                                    if (tensor[img][channel][h][w] < 1):\n",
    "                                            tensor[img][channel][h][w] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "SPLIT_IDX = 7500\n",
    "x_train = torch.tensor(x_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "x_test = torch.tensor(x_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "y_train = torch.tensor(y_input[:SPLIT_IDX], dtype=torch.float).permute(0,3,1,2)\n",
    "y_test = torch.tensor(y_input[SPLIT_IDX:], dtype=torch.float).permute(0,3,1,2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "x_train = x_train.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "# threshold(x_train)                       \n",
    "# threshold(x_test)\n",
    "# threshold(y_train)                       \n",
    "# threshold(y_test)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(x_train,y_train) # create your datset\n",
    "# train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True) # create your dataloader\n",
    "\n",
    "print (len(train_dataloader))\n",
    "\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "#/home/bwilab/asha_ritu/line_model/conv_network.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.cnn_stack = nn.Sequential( \n",
    "            # first layer: learning one person. \n",
    "            # kernel size = diameter of a dot (5 pixels) + padding (2 pixels) = (7,7)\n",
    "            # out_channels: 1 for now\n",
    "            # try changing the out_channels\n",
    "            # larger dataset and ReLU between each layer\n",
    "            # larger dataset, more layers, larger kernels\n",
    "\n",
    "            # find center pixel of each circle, count number of dots\n",
    "\n",
    "            # blob detect: looking for continuous regions of non-white pixels\n",
    "            # confidence regions. \n",
    "            # masking the image like in hw3\n",
    "            # \n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(6,6), stride=1, bias=True, padding=(2,2)), # input layer\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "\n",
    "            # layer 2: learning two dots.\n",
    "            # kernel_size = diameter of two dots (10 pixels) + distance between them (2 pixels) + padding (2 pixels)\n",
    "            # there are 8 different orientations two people can be in, resulting in 8 output channels.\n",
    "            # two options: either increase kernel size and number of channels or\n",
    "\n",
    "            # pool -> lower image resolution and learn a smaller pattern\n",
    "\n",
    "            # nn.MaxPool2d()\n",
    "\n",
    "            # nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(14,14), stride=1, bias=True, padding=(7,7)),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "\n",
    "\n",
    "            # nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(16, 16), stride=1, bias=True, padding=(7,7)),\n",
    "            # nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "\n",
    "            # 100 = 50 - 12 + 50\n",
    "            # final layer: out_channels=1, \n",
    "            # kernel size = ? ask Dr. Hart what a reasonable kernel size for the output layer could be.\n",
    "            nn.Conv2d(in_channels=4, out_channels=1, kernel_size=(6,6), padding=(3,3)), # 100 x 100\n",
    "            nn.ReLU()\n",
    "            # nn.Sigmoid() # values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.cnn_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "learning_rate = 3e-4\n",
    "weight_decay=1e-5\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), weight_decay=weight_decay, lr=learning_rate)\n",
    "batch_size = 16\n",
    "epochs = 25\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss() # can change this to another loss function\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        # print(X)\n",
    "        pred = model(X)\n",
    "        # print(f\"pred:{pred}\")\n",
    "        # print(f\"target:{y}\")\n",
    "    \n",
    "        # print(f\"pred: {pred}\")\n",
    "        # print(f\"y shape:{y.shape}\")\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "        # if batch % 50 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# def test_loop(dataloader, model, loss_fn):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     test_loss, correct = 0, 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in dataloader:\n",
    "#             # print(X.shape)\n",
    "#             pred = model(X)\n",
    "#             # print(pred.argmax(1).shape)\n",
    "#             # print(y.shape)\n",
    "#             test_loss += loss_fn(pred, y).item()\n",
    "#             correct += (pred == y).type(torch.float).sum().item()\n",
    "#             # print(correct)\n",
    "\n",
    "#     test_loss /= num_batches\n",
    "#     correct /= size\n",
    "#     print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#   model.eval()\n",
    "#   test_loss = 0\n",
    "#   correct = 0\n",
    "#   avg_accuracy = 0\n",
    "#   with torch.no_grad():\n",
    "#     for data, target in test_dataloader:\n",
    "#       output = model(data)\n",
    "#       test_loss += loss_fn(output, target).item()\n",
    "\n",
    "#       img = 0\n",
    "#       h = 0\n",
    "#       w = 0        \n",
    "\n",
    "#       # compare the number of dots, not the pixel by pixel comparison\n",
    "\n",
    "#       for img in range (5):\n",
    "#         correct = 0\n",
    "#         # print (target[img][0].shape)\n",
    "#         for h in range (100):\n",
    "#           for w in range (100):\n",
    "#             # print(f\"output {output[img][0]}\")\n",
    "#             # print(f\"target {target[img][0]}\")\n",
    "#             if (target[img][0][h][w] == 0 and output[img][0][h][w] == 0):\n",
    "#               correct += 1\n",
    "\n",
    "        # print(f\"percentage of pixels correct for image {img}: {correct/10000}\")\n",
    "\n",
    "        # print (f\"num correct: {correct}\")\n",
    "\n",
    "      # num_correct = output.eq(target.data.view_as(output)).sum()\n",
    "      \n",
    "  # test_loss /= len(test_dataloader.dataset)\n",
    "  # test_losses.append(test_loss)\n",
    "  # print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "  #   test_loss, correct, len(test_dataloader.dataset),\n",
    "  #   100. * correct / len(test_dataloader.dataset)))\n",
    "\n",
    "  # avg_accuracy /= 1000\n",
    "  # print(f\"average accuracy: {avg_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.641292\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.023932\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.020560\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.014993\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.010069\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.008213\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.007030\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.006054\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.005377\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.004687\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.004144\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.003707\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.003285\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.003051\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.002707\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.002570\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.002477\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.002246\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.002227\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.002109\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.002069\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.002026\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.001993\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.001939\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.001846\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# test()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test()\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:980753): GLib-GObject-CRITICAL **: 13:31:34.616: g_object_unref: assertion 'G_IS_OBJECT (object)' failed\n",
      "\n",
      "(eog:980753): EOG-WARNING **: 13:31:34.616: Error when getting information for file “/tmp/.gnome_desktop_thumbnail.94KAW1”: No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:980753): EOG-CRITICAL **: 13:31:34.684: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:980753): GLib-GIO-CRITICAL **: 13:31:34.684: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n"
     ]
    }
   ],
   "source": [
    "# model = NeuralNetwork()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "\n",
    "        i = 0\n",
    "        # print (target[0][0])\n",
    "        output = model(data)    \n",
    "        # print(output)\n",
    "        # print(f\"{output[4][0]}\")\n",
    "        # with open('model_output.npy', 'wb') as f:\n",
    "        #     np.save(f, output)\n",
    "\n",
    "        # INPUT\n",
    "        input_arr = np.array(data.cpu().data[i][0])*255\n",
    "        input = Image.fromarray(input_arr)\n",
    "        input.show()\n",
    "        # print(input_arr)\n",
    "\n",
    "\n",
    "        # ACTUAL OUTPUT\n",
    "       \n",
    "\n",
    "        # output = [(1-x) for x in output]\n",
    "        arr = np.array(output[i][0].cpu().data)\n",
    "\n",
    "\n",
    "        # for h in range(100):\n",
    "        #     for w in range(100):\n",
    "        #         if (arr[h][w] < 0.5):\n",
    "        #             print(\"black dot!\")\n",
    "\n",
    "        # print(arr.shape)\n",
    "\n",
    "        x_min = arr.min(axis=(0, 1), keepdims=True)\n",
    "        x_max = arr.max(axis=(0, 1), keepdims=True)\n",
    "        arr = (arr - x_min)/(x_max-x_min)\n",
    "\n",
    "        # arr[arr < 1] = 0\n",
    "        # print(arr)\n",
    "        arr = arr * 255\n",
    "        im = Image.fromarray(arr)\n",
    "        im.show()\n",
    "\n",
    "        # EXPECTED OUTPUT\n",
    "        # expected_arr = np.array(target.cpu().data[i][0]) * 255\n",
    "        # expected_arr[expected_arr < 1] = 0\n",
    "        # expected_arr = expected_arr * 255\n",
    "        # im_expected = Image.fromarray(expected_arr)\n",
    "        # im_expected.show()\n",
    "        \n",
    "\n",
    "       \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c6b82f28f63ce523f5c26d92ac0b14ad6785c6a25a5c8f6e4c562a3fc2245a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
